{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return(1/(1+torch.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=torch.rand((1,5))\n",
    "weights=torch.rand_like(features)\n",
    "bias = torch.rand((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6624, 0.2328, 0.8967, 0.2631, 0.6151]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8961]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(torch.matmul(features,weights.t()) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=torch.rand((2,5))\n",
    "bias=torch.rand((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9022, 0.6513]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9427, 0.7720]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(torch.mm(features,weights.t())+bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2804, 0.2763],\n",
       "        [0.2634, 0.7519],\n",
       "        [0.1153, 0.5867],\n",
       "        [0.6539, 0.6993],\n",
       "        [0.3234, 0.8312]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparr=np.random.rand(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3520, 0.3401, 0.5562, 0.4459, 0.6646],\n",
       "        [0.5880, 0.9199, 0.7996, 0.0240, 0.5681],\n",
       "        [0.7843, 0.7311, 0.2826, 0.3207, 0.8748],\n",
       "        [0.1039, 0.0372, 0.5668, 0.2530, 0.2853],\n",
       "        [0.2441, 0.6119, 0.2061, 0.2331, 0.2396]], dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(nparr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=datasets.MNIST('MNIST/',download=True,train=True,transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = torch.utils.data.DataLoader(data,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz=iter(trainLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,lbl=zz.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f63f7043390>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img[63].numpy().squeeze(),cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz=img[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=img.view(img.shape[0],784)\n",
    "w1=torch.randn((784,256))\n",
    "b1=torch.randn(256)\n",
    "\n",
    "w2=torch.randn(256,10)\n",
    "b2=torch.randn(10)\n",
    "\n",
    "hidden=sigmoid(torch.mm(inputs,w1)+b1)\n",
    "out=torch.mm(hidden,w2)+b2\n",
    "\n",
    "#sigmoid(torch.mm(img,w1)+b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max(x):\n",
    "    return(torch.exp(x)/torch.sum(torch.exp(x),dim=1).view(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_max(out).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.l1=nn.Linear(786,256)\n",
    "        self.l2=nn.Linear(256,10)\n",
    "        \n",
    "        self.sig=nn.Sigmoid()\n",
    "        self.sMax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out=self.l1(x)\n",
    "        out=self.sig(out)\n",
    "        out=self.l2(out)\n",
    "        return(self.sMax(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (l1): Linear(in_features=786, out_features=256, bias=True)\n",
       "  (l2): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sig): Sigmoid()\n",
       "  (sMax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1=nn.Linear(784,256)\n",
    "        self.l2=nn.Linear(256,10)\n",
    "    def forward(self,x):\n",
    "        out=torch.nn.functional.sigmoid(self.l1(x))\n",
    "        return(torch.nn.functional.softmax(self.l2(out),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network2(\n",
       "  (l1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (l2): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Network2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, layers): \n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        self.lin=nn.ModuleList()\n",
    "        self.activationValue = [torch.zeros(i) for i in layers[1:]]\n",
    "        self.layers = layers\n",
    "        self.nLayer = len(layers)-1\n",
    "        for i in range(len(layers)-1):\n",
    "            self.lin.append(nn.Linear(layers[i],layers[i+1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        for i in range(len(self.layers)-2):\n",
    "            x=self.lin[i](x)\n",
    "            x = torch.sigmoid(x)\n",
    "            self.activationValue[i]=x.clone()\n",
    "        x=self.lin[self.nLayer-1](x)\n",
    "        x=F.log_softmax(x,dim=1)\n",
    "        self.activationValue[self.nLayer-1]=x.clone()\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedforwardNeuralNetModel(\n",
       "  (lin): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (2): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FeedforwardNeuralNetModel([784,128,64,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.Tensor([1,2,9,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.Sequential(nn.Linear(784,128),nn.ReLU(),nn.Linear(128,64),nn.ReLU(),\n",
    "                    nn.Linear(64,10),nn.LogSoftmax(dim=1)\n",
    "                   )\n",
    "loss=nn.NLLLoss()\n",
    "imgs,lbl=next(iter(trainLoader))\n",
    "inputs=imgs.view(imgs.shape[0],-1)\n",
    "op=model(inputs)\n",
    "lc=loss(op,lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial weights\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=nn.Sequential(nn.Linear(784,128),nn.ReLU(),nn.Linear(128,64),nn.ReLU(),nn.Linear(64,10))\n",
    "loss=nn.CrossEntropyLoss()\n",
    "imgs,lbl=next(iter(trainLoader))\n",
    "inputs=imgs.view(imgs.shape[0],-1)\n",
    "op=model(inputs)\n",
    "loss(op,lbl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([99.,  2.,  9.,  3.])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-309.0611777305603\n",
      "-129.890625\n",
      "-93.46875\n",
      "-91.5\n",
      "-91.40625\n"
     ]
    }
   ],
   "source": [
    "model=nn.Sequential(nn.Linear(784,128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(128,64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64,10),\n",
    "                   nn.Softmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01)\n",
    "epochs =5\n",
    "\n",
    "for e in range(epochs):\n",
    "    r_loss=0\n",
    "    for images,labels in trainLoader:\n",
    "        images = images.view(images.shape[0],-1)\n",
    "        op=model(images)\n",
    "        loss = criterion(op,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        r_loss += loss.item()\n",
    "        \n",
    "    print(r_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=datasets.FashionMNIST('Fation_MNIST/',download=True,train=True,transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = torch.utils.data.DataLoader(data,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = datasets.FashionMNIST('Fation_MNIST/', train=False, download=True, transform=trans)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeedforwardNeuralNetModel([784,128,64,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565.4530468285084\n",
      "383.9132212251425\n",
      "358.45893912017345\n",
      "340.85695896297693\n",
      "327.7956899628043\n",
      "317.8935473486781\n",
      "305.6696578413248\n",
      "300.15833285450935\n",
      "296.4546749740839\n",
      "288.52294135838747\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for i in range(epochs):\n",
    "    r_loss= 0\n",
    "    for images,labels in trainLoader:\n",
    "        images = images.view(images.shape[0],-1)\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds,labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        r_loss += loss.item()\n",
    "    print(r_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter=iter(testloader)\n",
    "images,labels = dataiter.next()\n",
    "img = images[4].view(1,784)\n",
    "\n",
    "ps =torch.exp(model(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.detach().numpy()\n",
    "labels[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f63f4219c18>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[4].numpy().squeeze(),cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f63f6976468>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedforwardNeuralNetModel(\n",
       "  (lin): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (2): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.nLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0612e-09])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.Tensor([-20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
